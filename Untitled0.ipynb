{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "31zs__1BsUTH",
    "outputId": "7e8f61b0-15e0-4a55-db46-7e27576543f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-e27e064dacb2>:40: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend('sox_io')\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ndef process_mp3_folder(mp3_folder, output_folder):\\n    # List all files in the MP3 folder\\n    mp3_files = [f for f in os.listdir(mp3_folder) if f.endswith(\\'.mp3\\')]\\n\\n    # Process each MP3 file\\n    for mp3_file in mp3_files:\\n        mp3_path = os.path.join(mp3_folder, mp3_file)\\n        wav_path = os.path.join(output_folder, mp3_file.replace(\\'.mp3\\', \\'.wav\\'))\\n\\n        # Convert MP3 to WAV and apply denoising\\n        mp3_to_wav(mp3_path, wav_path)\\n\\n# Example usage\\nmp3_folder = \"/content/mp3_folder/\"\\noutput_folder = \"/content/wav_folder\"\\nprocess_mp3_folder(mp3_folder, output_folder)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "def denoise_audio(audio_tensor, sample_rate):\n",
    "    # Convert torch tensor to NumPy array\n",
    "    audio_np = audio_tensor.numpy()\n",
    "\n",
    "    # Denoise using librosa (you may need to install librosa: pip install librosa)\n",
    "    denoised_np = librosa.effects.preemphasis(audio_np)\n",
    "\n",
    "    # Convert NumPy array back to torch tensor\n",
    "    denoised_waveform = torch.tensor(denoised_np).view(1, -1)\n",
    "\n",
    "    return denoised_waveform\n",
    "\n",
    "'''\n",
    "def denoise_audio(audio_tensor, sample_rate):\n",
    "    # Short Time Fourier Transform\n",
    "    stft = T.Spectrogram()(audio_tensor)\n",
    "\n",
    "    # Compute magnitude spectrogram\n",
    "    magnitude = torch.abs(stft)\n",
    "\n",
    "    # Estimate noise using the minimum statistics\n",
    "    min_stat, _ = torch.min(magnitude, dim=2, keepdim=True)\n",
    "\n",
    "    # Subtract noise\n",
    "    denoised_spectrogram = torch.where(magnitude < min_stat, torch.zeros_like(magnitude), magnitude - min_stat)\n",
    "\n",
    "    # Inverse Short Time Fourier Transform\n",
    "    denoised_waveform = T.GriffinLim()(denoised_spectrogram)\n",
    "\n",
    "    return denoised_waveform\n",
    "'''\n",
    "\n",
    "def mp3_to_wav(mp3_path, wav_path):\n",
    "    torchaudio.set_audio_backend('sox_io')\n",
    "\n",
    "    # Load the MP3 file using torchaudio\n",
    "    waveform, sample_rate = torchaudio.load(mp3_path, normalize=True)\n",
    "\n",
    "    # Denoise the audio\n",
    "    denoised_waveform = denoise_audio(waveform, sample_rate)\n",
    "\n",
    "    # Save the denoised waveform as a WAV file using torchaudio\n",
    "    torchaudio.save(wav_path, denoised_waveform, sample_rate)\n",
    "\n",
    "# Example usage\n",
    "mp3_path = \"/content/sample-188690.mp3\"\n",
    "wav_path = \"/content/new_audio.wav\"\n",
    "mp3_to_wav(mp3_path, wav_path)\n",
    "\n",
    "\n",
    "'''\n",
    "def process_mp3_folder(mp3_folder, output_folder):\n",
    "    # List all files in the MP3 folder\n",
    "    mp3_files = [f for f in os.listdir(mp3_folder) if f.endswith('.mp3')]\n",
    "\n",
    "    # Process each MP3 file\n",
    "    for mp3_file in mp3_files:\n",
    "        mp3_path = os.path.join(mp3_folder, mp3_file)\n",
    "        wav_path = os.path.join(output_folder, mp3_file.replace('.mp3', '.wav'))\n",
    "\n",
    "        # Convert MP3 to WAV and apply denoising\n",
    "        mp3_to_wav(mp3_path, wav_path)\n",
    "\n",
    "# Example usage\n",
    "mp3_folder = \"/content/mp3_folder/\"\n",
    "output_folder = \"/content/wav_folder\"\n",
    "process_mp3_folder(mp3_folder, output_folder)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T08NtIjUsS80"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKdmWPjTr4-O",
    "outputId": "d85c55f6-ae92-4ce3-ef7a-19f84e994bbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-f2aeac67eb13>:25: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend('sox_io')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import os\n",
    "\n",
    "def denoise_audio(audio_tensor, sample_rate):\n",
    "    # Short Time Fourier Transform\n",
    "    stft = T.Spectrogram()(audio_tensor)\n",
    "\n",
    "    # Compute magnitude spectrogram\n",
    "    magnitude = torch.abs(stft)\n",
    "\n",
    "    # Estimate noise using the minimum statistics\n",
    "    min_stat, _ = torch.min(magnitude, dim=2, keepdim=True)\n",
    "\n",
    "    # Subtract noise\n",
    "    denoised_spectrogram = torch.where(magnitude < min_stat, torch.zeros_like(magnitude), magnitude - min_stat)\n",
    "\n",
    "    # Inverse Short Time Fourier Transform\n",
    "    denoised_waveform = T.GriffinLim()(denoised_spectrogram)\n",
    "\n",
    "    return denoised_waveform\n",
    "\n",
    "def mp3_to_wav(mp3_path, wav_path):\n",
    "    torchaudio.set_audio_backend('sox_io')\n",
    "\n",
    "    # Load the MP3 file using torchaudio\n",
    "    waveform, sample_rate = torchaudio.load(mp3_path, normalize=True)\n",
    "\n",
    "    # Denoise the audio\n",
    "    denoised_waveform = denoise_audio(waveform, sample_rate)\n",
    "\n",
    "    # Save the denoised waveform as a WAV file using torchaudio\n",
    "    torchaudio.save(wav_path, denoised_waveform, sample_rate)\n",
    "\n",
    "# Example usage\n",
    "#mp3_path = \"/content/sample-195525.mp3\"\n",
    "#wav_path = \"/content/new_audio.wav\"\n",
    "#mp3_to_wav(mp3_path, wav_path)\n",
    "\n",
    "\n",
    "\n",
    "def process_mp3_folder(mp3_folder, output_folder):\n",
    "    # List all files in the MP3 folder\n",
    "    mp3_files = [f for f in os.listdir(mp3_folder) if f.endswith('.mp3')]\n",
    "\n",
    "    # Process each MP3 file\n",
    "    for mp3_file in mp3_files:\n",
    "        mp3_path = os.path.join(mp3_folder, mp3_file)\n",
    "        wav_path = os.path.join(output_folder, mp3_file.replace('.mp3', '.wav'))\n",
    "\n",
    "        # Convert MP3 to WAV and apply denoising\n",
    "        mp3_to_wav(mp3_path, wav_path)\n",
    "\n",
    "# Example usage\n",
    "mp3_folder = \"/content/mp3_folder/\"\n",
    "output_folder = \"/content/wav_folder\"\n",
    "process_mp3_folder(mp3_folder, output_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3icZhnpq12xM",
    "outputId": "a93536af-6476-4e9b-92e8-7c2d1b386562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#folder_path = \"/content/mp3_folder/\"  # Replace with your folder path\n",
    "folder_path = \"/content/wav_folder/\"\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Print the list of files\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "vIh8jAgw32H_",
    "outputId": "4676c78f-c83e-465a-fa3d-71ba2b57cb42"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/wav_folder.zip'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Replace \"/content/mp3_files\" with the path to your folder\n",
    "folder_path = \"/content/wav_folder/\"\n",
    "\n",
    "# Create a zip file of the folder\n",
    "shutil.make_archive(\"/content/wav_folder\", 'zip', folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LgG5dsO4GkP"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Replace \"/content/mp3_files\" with the path to your folder\n",
    "folder_path = \"/content/mp3_folder/\"\n",
    "folder_path1 = \"/content/wav_folder/\"\n",
    "\n",
    "# Use shutil.rmtree to delete the folder and its contents\n",
    "shutil.rmtree(folder_path)\n",
    "shutil.rmtree(folder_path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZjTX3Ie9H8P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Tzritsk9F4Z"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the audio files\n",
    "file1 = \"/mnt/c/Users/vakky/Downloads/Deep Learning Speech Denoising/344-3-5-0.wav\"\n",
    "file2 = \"/mnt/c/Users/vakky/Downloads/Deep Learning Speech Denoising/sample-195525.wav\"\n",
    "\n",
    "waveform1, sample_rate1 = torchaudio.load(file1)\n",
    "waveform2, sample_rate2 = torchaudio.load(file2)\n",
    "\n",
    "# Check if the sample rates match and resample if necessary\n",
    "if sample_rate1 != sample_rate2:\n",
    "    print(\"Sample rates are different. Resampling...\")\n",
    "    waveform2 = torchaudio.transforms.Resample(sample_rate2, sample_rate1)(waveform2)\n",
    "\n",
    "# Ensure the waveforms have the same length\n",
    "min_length = min(waveform1.shape[1], waveform2.shape[1])\n",
    "waveform1 = waveform1[:, :min_length]\n",
    "waveform2 = waveform2[:, :min_length]\n",
    "\n",
    "# Merge the audio files by summing the waveforms\n",
    "merged_waveform = waveform1 + waveform2\n",
    "\n",
    "# Save the merged audio\n",
    "output_file = \"merged_audio.wav\"\n",
    "torchaudio.save(output_file, merged_waveform, sample_rate1)\n",
    "print(f\"Merged audio saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
